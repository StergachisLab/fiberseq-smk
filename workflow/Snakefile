import os
import sys
from snakemake.utils import min_version

min_version("7.8")

version: "0.1.0"

# process the input configuration file/options.
scatter_threads = config.pop("scatter_threads", 8)
max_threads = config.pop("max_threads", 24)
input_type = config.pop("input_type", "ccs")
env = config.pop("env", "envs/env.yml")
ref = config.pop("ref", None)
gmm_model = config.pop("gmm_model", False)
save_ipd = config.pop("save_ipd", False)
gff = config.pop("gff", False)
process_first_n = config.pop("process_first_n", None)
min_ml_score = config.pop("min_ml_score", 200)
# make big wig density files
bigwig = config.pop("bigwig", False)
# use the fibertool-rs prediction instead of ipdSummary
use_ipdsummary = config.pop("ipdsummary", False)
predict_with_hifi = False if use_ipdsummary else True
# max ipdsummary coverage
max_coverage = config.pop("max_coverage", 20)
# max number of alignments to load in 1 kbp window for ipdsummary
max_alignments = config.pop("max_alignments", 100)
# list of input samples
samples = list(config.keys())

# output wildcards
output_types = ["m6a", "cpg", "nuc", "msp"]
aligned = ["aligned", "unaligned"]


# functions used across the workflow
include: "rules/common.smk"


# check that the required tools are installed
check_for_tools()

# make sure bams are the right format
check_input_bams()

# check for old version of the pipeline and warn users to update outputs.
check_for_old_outputs()

# force the reference to exist.
check_for_reference()

# make sure pbi files exist for the input bams
check_input_bams_for_index()

# define number of chunks based on input file sizes
default_n_chunks = get_number_of_chunks()


scattergather:
    chunks=default_n_chunks,


# number of chunks used in scatter gather
n_chunks = len(scatter.chunks("temp/{scatteritem}.fake"))


# rules for running ccs
include: "rules/ccs.smk"
# pacbio tools: actc, ipdSummary, primrose
include: "rules/pacbio-tools.smk"
# make the fiberseq bam
include: "rules/fiberseq-bam.smk"
# make bed files from the fiberseq bam
include: "rules/bed-files.smk"
# run qc on the fiberseq bam
include: "rules/qc.smk"
# make data from ML models for calling m6A (optional)
include: "rules/ml.smk"


wildcard_constraints:
    sm="|".join(samples),
    data="|".join(output_types),
    aligned="|".join(aligned),


rule all:
    input:
        # fiberseq bam
        expand(rules.merge.output.bam, sm=samples),
        expand(rules.index_merge.output.pbi, sm=samples),
        # aligned fiberseq bam
        align_results(samples),
        # QC results
        expand(rules.qc_results.input, sm=samples),
        # bed
        expand(
            "results/{sm}/bed/{sm}.{aligned}.{data}.bed.gz",
            aligned=aligned,
            sm=samples,
            data=output_types,
        ),
        # bigbed
        expand(
            rules.bigbed.output.bb,
            sm=samples,
            data=output_types,
        ),
        # get ipdSummary files if requested
        get_ipd_results(samples),
        # get bigwig files if requested
        bigwig_results(bigwig),


rule help:
    message:
        "Displaying config options"
    run:
        for key, value in config.items():
            print(f"{key}: {value}")


rule help_benchmark:
    input:
        align=gather.chunks(rules.align.benchmark, allow_missing=True),
        bigbed=gather.chunks(
            rules.bigbed.benchmark, data=output_types, allow_missing=True
        ),
        fiber_table=gather.chunks(rules.fiber_table.benchmark, allow_missing=True),
        m6a=gather.chunks(
            rules.predict_m6a_with_fibertools_rs.benchmark, allow_missing=True
        ),
        primrose=gather.chunks(rules.primrose.benchmark, allow_missing=True),
    output:
        temp("results/{sm}/{sm}.runtimes.txt"),
    run:
        out = summarise_runtimes(input, wildcards.sm)
        with open(output[0], "w") as f:
            f.write(out)


rule benchmarks:
    input:
        expand(rules.help_benchmark.output, sm=samples),
    shell:
        "cat {input}"
