from snakemake.utils import min_version

min_version("7.8")


include: "rules/common.smk"


scattergather:
    chunks=20,


env = config.pop("env", "envs/env.yml")
n_chunks = len(scatter.chunks("temp/{scatteritem}.fake"))


wildcard_constraints:
    sm="|".join(config.keys()),


rule all:
    input:
        expand("results/{sm}/unaligned.m6a.bam", sm=list(config.keys())),
        expand("results/{sm}/unaligned.m6a.bam.pbi", sm=list(config.keys())),


rule ccs:
    input:
        bam=get_subreads,
    output:
        bam=temp("temp/{sm}/ccs.{scatteritem}.bam"),
        pbi=temp("temp/{sm}/ccs.{scatteritem}.bam.pbi"),
        json=temp("temp/{sm}/ccs.{scatteritem}.zmw_metrics.json.gz"),
        txt=temp("temp/{sm}/ccs.{scatteritem}.ccs_report.txt"),
    resources:
        mem_mb=8000,
    threads: config.get("threads", 8)
    conda:
        env
    log:
        "logs/{sm}/ccs.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/ccs.{scatteritem}.tbl"
    params:
        chunk=get_chunk,
    shell:
        """
        ccs {input.bam} {output.bam} \
            --metrics-json {output.json} \
            --report-file {output.txt} \
            --hifi-kinetics -j {threads} \
            --chunk {params.chunk} \
        &> {log}
        """


rule actc:
    input:
        ccs=rules.ccs.output.bam,
        subreads=get_subreads,
    output:
        bam=temp("temp/{sm}/actc.{scatteritem}.bam"),
        fasta=temp("temp/{sm}/actc.{scatteritem}.fasta"),
    threads: config.get("threads", 8)
    conda:
        env
    log:
        "logs/{sm}/actc.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/actc.{scatteritem}.tbl"
    shell:
        """
        actc -j {threads} {input.subreads} {input.ccs} {output.bam} 2> {log}
        """


rule index:
    input:
        bam=rules.actc.output.bam,
    output:
        pbi=temp(f"{rules.actc.output.bam}.pbi"),
    threads: 1
    conda:
        env
    log:
        "logs/{sm}/index.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/index.{scatteritem}.tbl"
    shell:
        """
        pbindex {input.bam} &> {log}
        """


rule ccs_fasta:
    input:
        ccs=rules.ccs.output.bam,
    output:
        fasta=temp("temp/{sm}/ccs.{scatteritem}.fasta"),
        fai=temp("temp/{sm}/ccs.{scatteritem}.fasta.fai"),
    threads: 4
    conda:
        env
    log:
        "logs/{sm}/ccs.fasta.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/ccs_fasta.{scatteritem}.tbl"
    shell:
        """
        samtools fasta -@ {threads} {input.ccs} > {output.fasta} 2> {log}
        samtools faidx {output.fasta} 2>> {log}
        """


rule ipdSummary:
    input:
        ccs_fasta=rules.ccs_fasta.output.fasta,
        fai=rules.ccs_fasta.output.fai,
        actc=rules.actc.output.bam,
        #bai=rules.index.output.bai,
        pbi=rules.index.output.pbi,
    output:
        csv=temp("temp/{sm}/ipdSummary.{scatteritem}.csv"),
    threads: config.get("threads", 8)
    conda:
        env
    log:
        "logs/{sm}/ipdSummary.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/ipdSummary.{scatteritem}.tbl"
    shell:
        """
        ipdSummary \
            --reference {input.ccs_fasta} \
            --pvalue 0.001 \
            --numWorkers {threads} \
            --quiet --identify m6A \
            --csv {output.csv} \
            {input.actc} &> {log}
        """


rule gmm:
    input:
        ccs=rules.ccs.output.bam,
        csv=rules.ipdSummary.output.csv,
    output:
        bam=temp("temp/{sm}/gmm.{scatteritem}.bam"),
    threads: 4
    conda:
        env
    log:
        "logs/{sm}/gmm.{scatteritem}.log",
    params:
        gmm=workflow.source_path("scripts/push_m6a_to_bam.py"),
    benchmark:
        "benchmarks/{sm}/gmm.{scatteritem}.tbl"
    shell:
        """
        python {params.gmm} --threads {threads} {input.csv} {input.ccs} > {output.bam} 2> {log}
        """


rule train_hmm:
    input:
        bam=f"temp/{{sm}}/gmm.1-of-{n_chunks}.bam",
    output:
        model=temp("temp/{sm}/hmm_model.json"),
    conda:
        env
    log:
        "logs/{sm}/train_hmm.log",
    params:
        nuc=workflow.source_path("scripts/add_nucleosomes.py"),
    benchmark:
        "benchmarks/{sm}/train_hmm.tbl"
    threads: 1
    shell:
        """
        python {params.nuc} --threads {threads} {input.bam} {output.model} 2> {log}
        """


rule nuc:
    input:
        bam=rules.gmm.output.bam,
        model=rules.train_hmm.output.model,
    output:
        bam=temp("temp/{sm}/nuc.{scatteritem}.bam"),
    conda:
        env
    log:
        "logs/{sm}/nuc.{scatteritem}.log",
    params:
        nuc=workflow.source_path("scripts/add_nucleosomes.py"),
    benchmark:
        "benchmarks/{sm}/nuc.{scatteritem}.tbl"
    threads: 4
    shell:
        """
        python {params.nuc} -m {input.model} --threads {threads} {input.bam} {output.bam} 2> {log}
        """


rule merge:
    input:
        bam=gather.chunks(rules.nuc.output.bam, allow_missing=True),
        pbi=gather.chunks(rules.ccs.output.pbi, allow_missing=True),
    output:
        bam="results/{sm}/unaligned.m6a.bam",
    conda:
        env
    log:
        "logs/{sm}/samtools.cat.log",
    resources:
        disk_mb=8000,
        time=120,
    threads: 4
    benchmark:
        "benchmarks/{sm}/merge.tbl"
    shell:
        """
        samtools cat -@ {threads} -o {output.bam} {input.bam} 2> {log}
        """


rule index_merge:
    input:
        bam=rules.merge.output.bam,
    output:
        pbi=f"{rules.merge.output.bam}.pbi",
    conda:
        env
    log:
        "logs/{sm}/samtools.cat.log",
    benchmark:
        "benchmarks/{sm}/index.tbl"
    threads: 1
    shell:
        """
        pbindex {input.bam} &> {log}
        """
