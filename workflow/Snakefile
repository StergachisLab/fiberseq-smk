# Main entrypoint of the workflow.
# Please follow the best practices:
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there.


include: "rules/common.smk"


scattergather:
    chunks=20,


wildcard_constraints:
    sm="|".join(config.keys()),


rule all:
    input:
        expand("results/{sm}/unaligned.m6a.bam", sm=list(config.keys())),
        expand("results/{sm}/unaligned.m6a.bam.pbi", sm=list(config.keys())),


rule ccs:
    input:
        bam=get_subreads,
    output:
        bam="temp/{sm}/ccs.{scatteritem}.bam",
    resources:
        mem=8000,
    threads: config.get("threads", 16)
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/ccs.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/ccs.{scatteritem}.tbl"
    params:
        chunk=get_chunk,
    shell:
        """
        ccs {input.bam} {output.bam} --hifi-kinetics -j {threads} --chunk {params.chunk} &> {log}
        """


rule zmws:
    input:
        bam=rules.ccs.output.bam,
    output:
        txt=temp("temp/{sm}/zmw.{scatteritem}.txt"),
    resources:
        mem=2000,
    threads: 1
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/zmw.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/zmw.{scatteritem}.tbl"
    shell:
        """
        bamsieve --show-zmws {input.bam} > {output.txt} 2> {log}
        """


rule subreads:
    input:
        bam=get_subreads,
        txt=rules.zmws.output.txt,
    output:
        bam=temp("temp/{sm}/subreads.{scatteritem}.bam"),
    resources:
        mem=2000,
    threads: 1
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/subreads.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/subreads.{scatteritem}.tbl"
    shell:
        """
        bamsieve --whitelist {input.txt} {input.bam} {output.bam} &> {log}
        """


rule actc:
    input:
        ccs=rules.ccs.output.bam,
        subreads=rules.subreads.output.bam,
    output:
        bam=temp("temp/{sm}/actc.{scatteritem}.bam"),
    resources:
        mem=8000,
    threads: config.get("threads", 16)
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/actc.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/actc.{scatteritem}.tbl"
    shell:
        """
        actc -j {threads} {input.subreads} {input.ccs} {output.bam} 2> {log}
        """


rule index:
    input:
        ccs=rules.actc.output.bam,
    output:
        #bai=temp(f"{rules.actc.output.bam}.bai"),
        pbi=temp(f"{rules.actc.output.bam}.pbi"),
    resources:
        mem=8000,
    threads: 1
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/index.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/index.{scatteritem}.tbl"
    shell:
        """
        pbindex {input.ccs} &> {log}
        #samtools index {input.ccs} &>> {log}
        """


rule ccs_fasta:
    input:
        ccs=rules.ccs.output.bam,
    output:
        fasta=temp("temp/{sm}/ccs.{scatteritem}.fasta"),
        fai=temp("temp/{sm}/ccs.{scatteritem}.fasta.fai"),
    resources:
        mem=1000,
    threads: 4
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/ccs.fasta.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/ccs_fasta.{scatteritem}.tbl"
    shell:
        """
        samtools fasta -@ {threads} {input.ccs} > {output.fasta} 2> {log}
        samtools faidx {output.fasta} 2>> {log}
        """


rule ipdSummary:
    input:
        ccs_fasta=rules.ccs_fasta.output.fasta,
        fai=rules.ccs_fasta.output.fai,
        actc=rules.actc.output.bam,
        #bai=rules.index.output.bai,
        pbi=rules.index.output.pbi,
    output:
        csv=temp("temp/{sm}/ipdSummary.{scatteritem}.csv"),
    resources:
        mem=1000,
    threads: config.get("threads", 16)
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/ipdSummary.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/ipdSummary.{scatteritem}.tbl"
    shell:
        """
        ipdSummary \
            --reference {input.ccs_fasta} \
            --pvalue 0.001 \
            --numWorkers {threads} \
            --quiet --identify m6A \
            --csv {output.csv} \
            {input.actc} &> {log}
        """


rule compress_csv:
    input:
        csv=rules.ipdSummary.output.csv,
    output:
        csv=temp(f"{rules.ipdSummary.output.csv}.gz"),
    resources:
        mem=1000,
    threads: 4
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/ipdSummary.{scatteritem}.log",
    benchmark:
        "benchmarks/{sm}/compress_csv.{scatteritem}.tbl"
    shell:
        """
        bgzip -@ {threads} {input.csv} > {output.csv} 2> {log}
        """


rule gmm:
    input:
        ccs=rules.ccs.output.bam,
        csv=rules.ipdSummary.output.csv,
    output:
        bam=temp("temp/{sm}/gmm.{scatteritem}.bam"),
    resources:
        mem=1000,
    threads: 4
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/gmm.{scatteritem}.log",
    params:
        gmm=workflow.source_path("scripts/push_m6a_to_bam.py"),
    benchmark:
        "benchmarks/{sm}/gmm.{scatteritem}.tbl"
    shell:
        """
        python {params.gmm} --threads {threads} {input.csv} {input.ccs} > {output.bam} 2> {log}
        """


rule merge:
    input:
        bam=gather.chunks(rules.gmm.output.bam, allow_missing=True),
    output:
        bam="results/{sm}/unaligned.m6a.bam",
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/samtools.cat.log",
    threads: 4
    benchmark:
        "benchmarks/{sm}/merge.tbl"
    shell:
        """
        samtools cat -@ {threads} -o {output.bam} {input.bam} 2> {log}
        """


rule index_merge:
    input:
        bam=rules.merge.output.bam,
    output:
        pbi=f"{rules.merge.output.bam}.pbi",
    conda:
        "envs/env.yml"
    log:
        "logs/{sm}/samtools.cat.log",
    benchmark:
        "benchmarks/{sm}/index.tbl"
    threads: 1
    shell:
        """
        pbindex {input.bam} &> {log}
        """
